import json
import re
import os

def check_vocabulary(file_path):
    print(f"æ­£åœ¨æ£€æŸ¥æ–‡ä»¶: {file_path} ...")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
        return

    # --- æ ¸å¿ƒä¿®å¤åŒºåŸŸ ---
    
    # 1. å»æ‰ 'export default'
    content = re.sub(r'export default\s*', '', content)
    
    # 2. ã€æ–°å¢ã€‘å»æ‰æ‰€æœ‰ä»¥ // å¼€å¤´çš„æ³¨é‡Š
    content = re.sub(r'//.*', '', content)
    
    # 3. å»æ‰æœ«å°¾åˆ†å·å’Œå¤šä½™ç©ºç™½
    content = content.strip().rstrip(';')

    # 4. ã€å®¹é”™ã€‘å°è¯•ä¿®å¤å¸¸è§çš„"å¤šä½™é€—å·"é—®é¢˜ (æ¯”å¦‚ },])
    # JSON ä¸å…è®¸æœ€åä¸€ä¸ªå…ƒç´ åé¢æœ‰é€—å·ï¼Œä½† JS å…è®¸
    content = re.sub(r',\s*]', ']', content) 
    
    # --- ä¿®å¤ç»“æŸ ---

    try:
        data = json.loads(content)
    except json.JSONDecodeError as e:
        print("\nâŒ è§£æå¤±è´¥ï¼è„šæœ¬æ²¡èƒ½å¤„ç†æ‰æŸäº›æ ¼å¼é—®é¢˜ã€‚")
        print(f"æŠ¥é”™ä½ç½®: line {e.lineno} column {e.colno}")
        print(f"æŠ¥é”™è¯¦æƒ…: {e}")
        # æŠŠæŠ¥é”™é™„è¿‘çš„å†…å®¹æ‰“å°å‡ºæ¥ç»™ä½ çœ‹
        lines = content.split('\n')
        if 0 <= e.lineno - 1 < len(lines):
            print(f"é—®é¢˜å¯èƒ½å‡ºåœ¨è¿™è¡Œé™„è¿‘: {lines[e.lineno - 1].strip()}")
        return

    # ä¸‹é¢æ˜¯æ­£å¸¸çš„æ£€æŸ¥é€»è¾‘
    word_map = {}
    id_map = {}
    suspicious = []
    
    total_count = len(data)
    
    for item in data:
        word = item.get('word', '').strip()
        wid = item.get('word_id')

        if word in word_map:
            word_map[word].append(wid)
        else:
            word_map[word] = [wid]

        if wid in id_map:
            id_map[wid].append(word)
        else:
            id_map[wid] = [word]

        issues = []
        if len(word) > 6: # æ”¾å®½ä¸€ç‚¹ç‚¹æ ‡å‡†åˆ°6
            issues.append("å¤ªé•¿")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«éæ³•å­—ç¬¦ (ä¿ç•™æ±‰å­—ã€è‹±æ–‡å­—æ¯ã€æ•°å­—)
        # è¿™ä¸€è¡Œæ’é™¤äº†æ ‡ç‚¹ç¬¦å·
        if not re.match(r'^[\u4e00-\u9fa5a-zA-Z0-9]+$', word):
            issues.append("å«ç‰¹æ®Šå­—ç¬¦")
            
        if issues:
            suspicious.append(f"{word} ({wid}): {', '.join(issues)}")

    print("-" * 30)
    print(f"ğŸ“Š æ£€æŸ¥å®Œæˆ! å…±æ‰«æ {total_count} ä¸ªè¯")
    print("-" * 30)

    duplicates = {k: v for k, v in word_map.items() if len(v) > 1}
    if duplicates:
        print(f"\nğŸš« å‘ç° {len(duplicates)} ä¸ªé‡å¤è¯æ±‡:")
        for word, ids in duplicates.items():
            print(f"  - '{word}' å‡ºç°äº† {len(ids)} æ¬¡ (IDs: {ids})")
    else:
        print("\nâœ… è¯æ±‡æ— é‡å¤ã€‚")

    id_dups = {k: v for k, v in id_map.items() if len(v) > 1}
    if id_dups:
        print(f"\nğŸš« å‘ç° {len(id_dups)} ä¸ªé‡å¤ ID (è¿™ä¼šå¯¼è‡´Bug):")
        for wid, words in id_dups.items():
            print(f"  - ID {wid} å†²çª: {words}")
    else:
        print("\nâœ… ID æ— å†²çªã€‚")

    if suspicious:
        print(f"\nâš ï¸ å‘ç° {len(suspicious)} ä¸ªå¯èƒ½ä¸è§„èŒƒçš„è¯:")
        for item in suspicious:
            print(f"  - {item}")
    else:
        print("\nâœ… æ‰€æœ‰è¯æ±‡æ ¼å¼è§„èŒƒã€‚")

if __name__ == "__main__":
    # è®°å¾—æ”¹æˆä½ çš„çœŸå®æ–‡ä»¶å
    check_vocabulary("life_fixed.js")